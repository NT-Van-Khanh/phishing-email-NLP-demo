{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "eY1C50dpJzKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mailbox\n",
        "import email\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "import nltk.sentiment as sentiment                          #from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# import gensim\n",
        "import gensim.parsing.preprocessing as gs_preprocessing     #from gensim.parsing.preprocessing import *\n",
        "import gensim.corpora as corpora\n",
        "import gensim.models as models                              #from gensim.models import Word2Vec,LdaMulticore\n",
        "#from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# import sklearn\n",
        "import sklearn.feature_extraction.text as text              #from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import sklearn.model_selection as model_selection           #from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "import sklearn.preprocessing as sk_preprocessing            #from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import sklearn.ensemble as ensemble\n",
        "import sklearn.metrics as metrics                           #from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "je-Elkn0J3nU",
        "outputId": "dc7804c5-75a7-43d3-abc5-01dce87504c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "YraJJFnTQwvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Email"
      ],
      "metadata": {
        "id": "5ZEwrhkOWzXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions: Extract email from .mbox file and .eml file\n"
      ],
      "metadata": {
        "id": "YBf_LlOI-Cnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_emails_from_mbox(mbox_file_name):\n",
        "  messages=[]\n",
        "  try:\n",
        "    mbox = mailbox.mbox(mbox_file_name)\n",
        "    for message in mbox:\n",
        "      messages.append(message)\n",
        "  except FileNotFoundError:\n",
        "    print(f\"File not found: {mbox_file_name}\")\n",
        "  return messages\n",
        "\n",
        "\n",
        "def extract_email_from_eml(eml_file_name):\n",
        "  email_message=None\n",
        "  try:\n",
        "      with open(eml_file_name, \"r\") as email_file:\n",
        "          email_message = email.message_from_file(email_file)\n",
        "  except FileNotFoundError:\n",
        "      print(f\"File not found: {eml_file_name}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "  return email_message\n",
        "\n",
        "#From:https://stackoverflow.com/questions/7166922/extracting-the-body-of-an-email-from-mbox-file-decoding-it-to-plain-text-regard"
      ],
      "metadata": {
        "id": "M0vGJHcsbPak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions: Extract component of email"
      ],
      "metadata": {
        "id": "mJYw16uQIDEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sender_email(email_message):\n",
        "  return email_message.get(\"From\")\n",
        "\n",
        "\n",
        "def extract_subject_email(email_message):\n",
        "  return email_message.get(\"Subject\")\n",
        "\n",
        "\n",
        "def extract_content_email(email_message):\n",
        "  body = None\n",
        "  if(email_message.is_multipart()):\n",
        "    for part in email_message.walk():\n",
        "      if(part.is_multipart()):\n",
        "        for subpart in part.walk():\n",
        "          if(subpart.get_content_type() == \"text/plain\"):\n",
        "            body = subpart.get_payload(decode=True)\n",
        "          # elif(subpart.get_content_type() == \"text/html\"):\n",
        "          #   body = subpart.get_payload(decode=True)\n",
        "      elif(part.get_content_type() == \"text/plain\"):\n",
        "        body = part.get_payload(decode=True)\n",
        "  else:\n",
        "    body = email_message.get_payload(decode=True)\n",
        "  if(body is not None):\n",
        "    #chuyển dữ liệu dạng byte string sang string (utf-8)\n",
        "    body=body.decode('utf-8')\n",
        "  return body"
      ],
      "metadata": {
        "id": "sBT5Yl7GTPfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process: Extract phishing emails"
      ],
      "metadata": {
        "id": "HtC14PZmJG_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phishing_message_bodies = []\n",
        "\n",
        "\n",
        "phishing_messages = extract_emails_from_mbox(\"/content/emails-enron-legal-mails.mbox\")\n",
        "for message in phishing_messages:\n",
        "  body=extract_content_email(message)\n",
        "  if (body is not None and body.strip()):\n",
        "    phishing_message_bodies.append(body)\n",
        "    #print(body)\n",
        "    #print(body).decode('utf-8')\n",
        "\n",
        "print(len(phishing_message_bodies))\n",
        "print(len(phishing_messages))"
      ],
      "metadata": {
        "id": "b2FoHAWSGrUw",
        "outputId": "6e97a5e9-29da-4200-dc40-76c5149d92df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4279\n",
            "4279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process: Extract benign emails"
      ],
      "metadata": {
        "id": "dYVDbnwbEUie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benign_message_bodies = []\n",
        "\n",
        "\n",
        "benign_messages = extract_emails_from_mbox(\"/content/emails-enron-ham.mbox\")\n",
        "for message in benign_messages:\n",
        "  body=extract_content_email(message)\n",
        "  if (body is not None and body.strip()):\n",
        "    benign_message_bodies.append(body)\n",
        "\n",
        "print(len(benign_message_bodies))\n",
        "print(len(benign_messages))"
      ],
      "metadata": {
        "id": "pmmlNwehETr0",
        "outputId": "58bf8ab0-3061-4390-ecf6-371483daeab5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ===TEST==="
      ],
      "metadata": {
        "id": "VQOB1m2h1Tug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msg = extract_email_from_eml(\"/content/sample1.eml\")\n",
        "messages = extract_emails_from_mbox(\"/emails-enron-legal-mails.mbox\")\n",
        "if(msg):\n",
        "  print(extract_sender_email(msg))\n",
        "  print(extract_subject_email(msg))\n",
        "  print(extract_content_email(msg))"
      ],
      "metadata": {
        "id": "LzTM6l8fKWtI",
        "outputId": "c8ae15dd-a774-419f-b901-4c3f2b6482fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File not found: /content/sample1.eml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(phishing_messages[0])\n",
        "print(phishing_message_bodies[0])"
      ],
      "metadata": {
        "id": "ZFt1xuQ61WBe",
        "outputId": "ae5a6ef6-4840-472e-e1a9-b375c44cccbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message-ID: <27151276.1075857703081.JavaMail.evans@thyme>\n",
            "Date: Thu, 28 Dec 2000 16:37:00 -0800 (PST)\n",
            "From: phillip.allen@enron.com\n",
            "To: john.lavorato@enron.com\n",
            "Subject: \n",
            "Mime-Version: 1.0\n",
            "Content-Type: text/plain; charset=ANSI_X3.4-1968\n",
            "Content-Transfer-Encoding: 7bit\n",
            "X-From: Phillip K Allen\n",
            "X-To: Lavorato, John </o=ENRON/ou=NA/cn=Recipients/cn=Jlavora>\n",
            "X-cc: \n",
            "X-bcc: \n",
            "X-Folder: \\jlavora\\COMP\n",
            "X-Origin: Lavorado-J\n",
            "X-FileName: jlavora.pst\n",
            "\n",
            "?\tPay well ? and pay for performance (with bonuses based on merit, not entitlement).\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Just a soundbite from a PRC email.  I am getting worried about Mike G. and myself.  Are you open to more discussions?\n",
            "\n",
            "Phillip\n",
            "\n",
            "\n",
            "?\tPay well ? and pay for performance (with bonuses based on merit, not entitlement).\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "Just a soundbite from a PRC email.  I am getting worried about Mike G. and myself.  Are you open to more discussions?\r\n",
            "\r\n",
            "Phillip\r\n",
            "\r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(benign_messages[0])\n",
        "print(benign_message_bodies[0])"
      ],
      "metadata": {
        "id": "3t1IbwnB1Z2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple preprocessing"
      ],
      "metadata": {
        "id": "jdd-9_Ye04iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom stop words and preprocessing filters"
      ],
      "metadata": {
        "id": "V3njuzeQQOvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom stop words and preprocessing filters\n",
        "stopWords = nltk.corpus.stopwords\n",
        "stopWords = stopWords.words(\"english\")\n",
        "stopWords.extend([\"nbsp\", \"font\", \"sans\", \"serif\", \"bold\", \"arial\", \"verdana\", \"helvetica\", \"http\", \"https\", \"www\", \"html\", \"enron\", \"margin\", \"spamassassin\"])\n",
        "\n",
        "def remove_custom_stopwords(p):\n",
        "    return gs_preprocessing.remove_stopwords(p, stopwords=stopWords)\n",
        "\n",
        "CUSTOM_FILTERS = [lambda x: x.lower(), gs_preprocessing.strip_tags, gs_preprocessing.strip_punctuation,\n",
        "                  gs_preprocessing.strip_multiple_whitespaces, gs_preprocessing.strip_numeric, remove_custom_stopwords,\n",
        "                  gs_preprocessing.remove_stopwords, gs_preprocessing.strip_short, gs_preprocessing.stem_text]\n"
      ],
      "metadata": {
        "id": "ZftALxyg079z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_preprocessing(messages):\n",
        "  preprocessed_messages = []\n",
        "  for message in messages:\n",
        "    preprocessed = gs_preprocessing.preprocess_string(message,filters = CUSTOM_FILTERS)\n",
        "    #NEED FIX: xu ly trung lap chi can thiet o black list\n",
        "    # if preprocessed and (preprocessed not in preprocessed_messages):\n",
        "    #   preprocessed_messages.append(preprocessed)\n",
        "    preprocessed_messages.append(preprocessed)\n",
        "\n",
        "  return preprocessed_messages\n",
        "\n",
        "#Bỏ các phần tử rỗng và trùng lập\n",
        "def duplicate_filter(texts):\n",
        "    unique_texts = []\n",
        "    for text in texts:\n",
        "        if text and (text not in unique_texts):\n",
        "            unique_texts.append(text)\n",
        "    return unique_texts\n"
      ],
      "metadata": {
        "id": "UHD1wYOMJUom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess messages"
      ],
      "metadata": {
        "id": "18F0fKdqQTY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing phishing message bodies\n",
        "phishing_preprocessed = []\n",
        "phishing_preprocessed =  custom_preprocessing(phishing_message_bodies)\n",
        "\n",
        "print(len(phishing_preprocessed))"
      ],
      "metadata": {
        "id": "MkbJl5lZ0_SL",
        "outputId": "cb5eb15f-44b2-4b51-ced3-f928f920bc71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing benign message bodies\n",
        "benign_preprocessed = []\n",
        "benign_preprocessed =  custom_preprocessing(benign_message_bodies)\n",
        "\n",
        "print(len(benign_preprocessed))"
      ],
      "metadata": {
        "id": "t2FnvYnt1BWr",
        "outputId": "d42b1eb3-1396-430d-9a60-10ff52894e3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ===TEST==="
      ],
      "metadata": {
        "id": "BWgiCUiuQn7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "print(len(phishing_message_bodies))\n",
        "print(len(duplicate_filter(phishing_message_bodies)))\n",
        "print(len(phishing_preprocessed))\n",
        "print(len(duplicate_filter(phishing_preprocessed)))\n",
        "\n",
        "print(phishing_preprocessed[0])"
      ],
      "metadata": {
        "id": "_0U5tciJ1DKp",
        "outputId": "c179977e-31e7-4c6c-843d-5ca43fcfc623",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4279\n",
            "4246\n",
            "4279\n",
            "4088\n",
            "['pai', 'pai', 'perform', 'bonus', 'base', 'merit', 'entitl', 'soundbit', 'prc', 'email', 'get', 'worri', 'mike', 'open', 'discuss', 'phillip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec Embedding\n"
      ],
      "metadata": {
        "id": "wtANJcvfjMD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_message_preprocessed = phishing_preprocessed + benign_preprocessed\n",
        "\n",
        "print(len(all_message_preprocessed))"
      ],
      "metadata": {
        "id": "r6qsxlGvVccA",
        "outputId": "e5d4d270-4270-43b3-dc80-d3c4dbf4a7d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on all messages\n",
        "word2vec_model = models.Word2Vec(all_message_preprocessed, vector_size=100, min_count=1, workers=3, window=5)\n",
        "#From: https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/"
      ],
      "metadata": {
        "id": "kRgK9ldSkCtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model.wv.most_similar(\"dollar\", topn=20)"
      ],
      "metadata": {
        "id": "3e4GPHLjluvu",
        "outputId": "23d0d51c-cd0d-4fbc-d0f9-915970d8236e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('billion', 0.9507895112037659),\n",
              " ('win', 0.9110546112060547),\n",
              " ('ubid', 0.903036892414093),\n",
              " ('maximum', 0.8959468603134155),\n",
              " ('tend', 0.8940055966377258),\n",
              " ('quantiti', 0.8918537497520447),\n",
              " ('supersit', 0.8888633251190186),\n",
              " ('defici', 0.8846665024757385),\n",
              " ('prioriti', 0.8796712160110474),\n",
              " ('half', 0.8794583082199097),\n",
              " ('auction', 0.8794552087783813),\n",
              " ('size', 0.8770312666893005),\n",
              " ('dissent', 0.8762837648391724),\n",
              " ('entri', 0.8752008080482483),\n",
              " ('dcq', 0.8745139837265015),\n",
              " ('store', 0.8734740018844604),\n",
              " ('majeur', 0.8722878098487854),\n",
              " ('grab', 0.8720036149024963),\n",
              " ('shorter', 0.8716081380844116),\n",
              " ('furthermor', 0.8704047203063965)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model.wv[\"dollar\"]"
      ],
      "metadata": {
        "id": "ykaw9PxJlvup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA Topic Modeling"
      ],
      "metadata": {
        "id": "j8sFzX6jU8mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init the number of topics"
      ],
      "metadata": {
        "id": "ZpBNSKMUWhQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numTopics = 1024"
      ],
      "metadata": {
        "id": "_d1CZXaGVRy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create dictionary and corpus"
      ],
      "metadata": {
        "id": "aguwb1mdVu4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = corpora.Dictionary(all_message_preprocessed)\n",
        "corpus = [dictionary.doc2bow(text) for text in all_message_preprocessed]"
      ],
      "metadata": {
        "id": "5aw2MNILTy1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dictionary)\n",
        "print(corpus[0])"
      ],
      "metadata": {
        "id": "YPhs2VaHPZqj",
        "outputId": "cd65a31e-b7d2-4721-bd95-9df3389937a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary<31032 unique tokens: ['base', 'bonus', 'discuss', 'email', 'entitl']...>\n",
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Create LDA model"
      ],
      "metadata": {
        "id": "efVePDN9VySO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LDA_model = models.LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=numTopics)"
      ],
      "metadata": {
        "id": "TbqOjNTPXTVA",
        "outputId": "b658f4fc-4438-4ad4-aa73-8c1539709c32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "# Print keyword for the topics\n",
        "print(LDA_model.print_topics())"
      ],
      "metadata": {
        "id": "SNJqzs9mZ3wR",
        "outputId": "ea32909a-f762-45b7-b37d-a43b4b0826d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(803, '0.011*\"com\" + 0.010*\"mail\" + 0.010*\"messag\" + 0.009*\"offic\" + 0.009*\"box\" + 0.008*\"power\" + 0.008*\"energi\" + 0.007*\"ferc\" + 0.007*\"compani\" + 0.007*\"gener\"'), (363, '0.010*\"com\" + 0.008*\"ee\" + 0.007*\"hou\" + 0.005*\"gener\" + 0.005*\"mail\" + 0.004*\"power\" + 0.004*\"leagu\" + 0.004*\"fantasi\" + 0.004*\"basketbal\" + 0.003*\"updat\"'), (744, '0.024*\"com\" + 0.024*\"mari\" + 0.019*\"rate\" + 0.018*\"file\" + 0.018*\"lft\" + 0.017*\"negoti\" + 0.017*\"subject\" + 0.014*\"dai\" + 0.014*\"know\" + 0.013*\"darveaux\"'), (657, '0.018*\"com\" + 0.012*\"need\" + 0.009*\"agreement\" + 0.009*\"continu\" + 0.008*\"issu\" + 0.008*\"power\" + 0.007*\"rick\" + 0.006*\"number\" + 0.006*\"state\" + 0.006*\"peopl\"'), (579, '0.094*\"com\" + 0.008*\"hotmail\" + 0.007*\"scott\" + 0.006*\"susan\" + 0.005*\"john\" + 0.005*\"pipelin\" + 0.005*\"lisa\" + 0.005*\"laura\" + 0.005*\"iso\" + 0.004*\"project\"'), (421, '0.078*\"com\" + 0.006*\"price\" + 0.006*\"richard\" + 0.005*\"new\" + 0.005*\"power\" + 0.005*\"robert\" + 0.004*\"access\" + 0.004*\"john\" + 0.004*\"mari\" + 0.004*\"plan\"'), (809, '0.038*\"exhibit\" + 0.025*\"parti\" + 0.024*\"com\" + 0.023*\"socalga\" + 0.021*\"june\" + 0.018*\"hear\" + 0.017*\"todai\" + 0.016*\"discuss\" + 0.016*\"version\" + 0.014*\"present\"'), (262, '0.047*\"com\" + 0.007*\"steff\" + 0.006*\"robert\" + 0.005*\"kuykendal\" + 0.005*\"transwestern\" + 0.005*\"tkuyken\" + 0.005*\"smith\" + 0.005*\"jennif\" + 0.004*\"non\" + 0.004*\"scott\"'), (426, '0.017*\"ect\" + 0.014*\"leg\" + 0.013*\"doc\" + 0.012*\"deal\" + 0.012*\"hou\" + 0.010*\"com\" + 0.010*\"form\" + 0.009*\"need\" + 0.008*\"subject\" + 0.008*\"perd\"'), (150, '0.010*\"ex\" + 0.008*\"updat\" + 0.008*\"game\" + 0.007*\"fantasi\" + 0.007*\"free\" + 0.007*\"com\" + 0.005*\"week\" + 0.005*\"start\" + 0.005*\"open\" + 0.004*\"texa\"'), (333, '0.037*\"com\" + 0.015*\"ect\" + 0.014*\"email\" + 0.013*\"sai\" + 0.012*\"beer\" + 0.012*\"hou\" + 0.012*\"want\" + 0.010*\"internet\" + 0.010*\"wife\" + 0.010*\"bar\"'), (170, '0.029*\"proteron\" + 0.021*\"wordsmith\" + 0.016*\"org\" + 0.012*\"awad\" + 0.011*\"hysteron\" + 0.010*\"husteron\" + 0.010*\"neuter\" + 0.010*\"word\" + 0.008*\"chang\" + 0.007*\"unsubscrib\"'), (494, '0.012*\"com\" + 0.007*\"imag\" + 0.006*\"iso\" + 0.005*\"ferc\" + 0.005*\"servic\" + 0.005*\"month\" + 0.005*\"power\" + 0.004*\"market\" + 0.003*\"ect\" + 0.003*\"report\"'), (671, '0.012*\"state\" + 0.011*\"california\" + 0.009*\"iso\" + 0.008*\"power\" + 0.008*\"market\" + 0.008*\"oper\" + 0.007*\"gener\" + 0.007*\"refund\" + 0.007*\"includ\" + 0.006*\"issu\"'), (526, '0.011*\"ect\" + 0.011*\"mail\" + 0.008*\"hou\" + 0.008*\"contract\" + 0.006*\"zapata\" + 0.006*\"action\" + 0.006*\"tam\" + 0.005*\"law\" + 0.005*\"com\" + 0.005*\"qui\"'), (226, '0.023*\"com\" + 0.017*\"kaminski\" + 0.014*\"tanya\" + 0.013*\"content\" + 0.011*\"var\" + 0.011*\"vinc\" + 0.010*\"ect\" + 0.009*\"need\" + 0.009*\"tamarchenko\" + 0.008*\"grant\"'), (701, '0.026*\"ect\" + 0.011*\"power\" + 0.010*\"forward\" + 0.010*\"com\" + 0.009*\"hou\" + 0.008*\"subject\" + 0.008*\"iso\" + 0.008*\"jcc\" + 0.007*\"mari\" + 0.005*\"need\"'), (511, '0.050*\"com\" + 0.026*\"jmbm\" + 0.021*\"internet\" + 0.018*\"nco\" + 0.009*\"power\" + 0.007*\"enronxg\" + 0.007*\"state\" + 0.007*\"california\" + 0.006*\"energi\" + 0.005*\"capac\"'), (477, '0.081*\"com\" + 0.007*\"david\" + 0.006*\"land\" + 0.005*\"scott\" + 0.005*\"susan\" + 0.005*\"subject\" + 0.004*\"travi\" + 0.004*\"sempra\" + 0.004*\"rick\" + 0.004*\"letter\"'), (880, '0.012*\"work\" + 0.012*\"origin\" + 0.011*\"michel\" + 0.011*\"com\" + 0.011*\"sherron\" + 0.010*\"subject\" + 0.009*\"thank\" + 0.008*\"guaranti\" + 0.008*\"messag\" + 0.007*\"watkin\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Doc2Vec"
      ],
      "metadata": {
        "id": "K-V4GinQabbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_data = [models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(all_message_preprocessed)]"
      ],
      "metadata": {
        "id": "aC8vWlZ3aezK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Khởi tạo và huấn luyện trực tiếp\n",
        "doc2vec_model = models.Doc2Vec(tagged_data, vector_size=20, window=2, min_count=1, workers=4)\n",
        "\n",
        "#Tách khởi tạo và huấn luyện1\n",
        "# doc2vec_model = models.Doc2Vec(tagged_data, vector_size=100, min_count=1, epochs=10)\n",
        "# doc2vec_model.build_vocab(tagged_data)\n",
        "# doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)"
      ],
      "metadata": {
        "id": "5_JOKTTzfDMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification"
      ],
      "metadata": {
        "id": "EDQ0WAcNK4Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_message_bodies = phishing_message_bodies + benign_message_bodies"
      ],
      "metadata": {
        "id": "04yicyRHSvSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blacklist words"
      ],
      "metadata": {
        "id": "QeuddVD5-Knt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_lines(file_path):\n",
        "  lines=[]\n",
        "  try:\n",
        "    with open(file_path, 'r') as file:\n",
        "      for line in file:\n",
        "        lines.append(line.strip())\n",
        "  except FileNotFoundError:\n",
        "    print(f\"File not found: {file_path}\")\n",
        "  return lines"
      ],
      "metadata": {
        "id": "h9VMJIFaDX3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "black_list_words = get_file_lines(\"/content/spam_wordlist.txt\")\n",
        "black_list = custom_preprocessing(black_list_words)\n",
        "black_list = duplicate_filter(black_list)\n",
        "\n",
        "print(len(black_list_words))\n",
        "print(len(black_list))"
      ],
      "metadata": {
        "id": "D87FfTy6Rj9T",
        "outputId": "f1f6509b-6958-4518-9605-5232c83ff2e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "582\n",
            "369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "00E_wzpVqh8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF\n",
        "max_term=6"
      ],
      "metadata": {
        "id": "SpzXq0S4VWxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_to_string(lst):\n",
        "    return ' '.join(lst)\n",
        "\n",
        "def count_all_upper_words(text):\n",
        "    count = 0\n",
        "    for word in text.split():\n",
        "        if word.isupper():\n",
        "            count += 1\n",
        "    return count"
      ],
      "metadata": {
        "id": "x0PWX0K9ctOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfVectorizer = text.TfidfVectorizer(max_features=max_term, preprocessor=list_to_string, sublinear_tf=True)\n",
        "tfidf_matrix = tfidfVectorizer.fit_transform(all_message_preprocessed).toarray()\n",
        "\n",
        "print(tfidfVectorizer.get_feature_names_out())\n",
        "print(tfidf_matrix.shape)\n",
        "print(tfidf_matrix[2])"
      ],
      "metadata": {
        "id": "eRfu_3cSYF0q",
        "outputId": "888a6ba8-6b63-4529-f74c-e1491a5ec567",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['com' 'content' 'ect' 'hou' 'mail' 'subject']\n",
            "(4279, 6)\n",
            "[0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector"
      ],
      "metadata": {
        "id": "GnnS-cy7-Etr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vectors_from_messages(messages, messages_preprocessed):\n",
        "    corpus = [dictionary.doc2bow(text) for text in messages_preprocessed] # Term document frequency\n",
        "    all_vectors = []\n",
        "    for i in range(len(messages)):\n",
        "        topTopics = LDA_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
        "\n",
        "        # Can extend this array with other stuff later\n",
        "        vec = [topTopics[i][1] for i in range(numTopics)] # Topics\n",
        "\n",
        "        for v in doc2vec_model.infer_vector(messages_preprocessed[i]): # Doc2Vec\n",
        "            vec.append(v)\n",
        "\n",
        "        # Sentiment analysis of polarity\n",
        "        sia = sentiment.SentimentIntensityAnalyzer()\n",
        "        sentence = \" \".join(messages_preprocessed[i])\n",
        "        polarity = sia.polarity_scores(sentence)\n",
        "        for s in polarity:\n",
        "            vec.append(polarity[s])\n",
        "\n",
        "        # Contains HTML\n",
        "        if \"<html>\" in messages[i].lower():\n",
        "            vec.append(1)\n",
        "        else:\n",
        "            vec.append(0)\n",
        "\n",
        "        # Contains a link\n",
        "        if \"http://\" in messages[i].lower() or \"https://\" in messages[i].lower():\n",
        "            vec.append(1)\n",
        "        else:\n",
        "            vec.append(0)\n",
        "\n",
        "        # How many blacklisted phrases/words appear in this email\n",
        "        for b in black_list:\n",
        "            count = 0\n",
        "            for word in b:\n",
        "                if word in messages_preprocessed[i]:\n",
        "                    count += 1\n",
        "            vec.append(count)\n",
        "\n",
        "        # TF-IDF for top terms\n",
        "        for word_weight in tfidf_matrix[i]:\n",
        "            vec.append(word_weight)\n",
        "\n",
        "        # Has all caps word?\n",
        "        vec.append(count_all_upper_words(messages[i]))\n",
        "\n",
        "        # Has exclamation marks?\n",
        "        vec.append(messages[i].count(\"!\"))\n",
        "\n",
        "        # Total length\n",
        "        vec.append(len(messages[i]))\n",
        "\n",
        "        # Num words\n",
        "        vec.append(len(messages_preprocessed[i]))\n",
        "\n",
        "        all_vectors.append(vec)\n",
        "\n",
        "    return all_vectors"
      ],
      "metadata": {
        "id": "UD7_5yfM9Cw6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_vectors = []\n",
        "for i in range(len(all_message_bodies)):\n",
        "  top_topics = LDA_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
        "  vec =  [top_topics[i][1] for i in range(numTopics)]#topics\n",
        "\n",
        "  for v in doc2vec_model.infer_vector(all_message_preprocessed[i]):#Doc2Vec--need to fix\n",
        "    vec.append(v)\n",
        "\n",
        "  sia = sentiment.SentimentIntensityAnalyzer()\n",
        "  sentence = \" \".join(all_message_preprocessed[i])\n",
        "  polarity = sia.polarity_scores(sentence)\n",
        "\n",
        "  for s in polarity:\n",
        "    vec.append(polarity[s])\n",
        "\n",
        "  # Contains HTML\n",
        "  if \"<html>\" in all_message_bodies[i].lower():\n",
        "      vec.append(1)\n",
        "  else:\n",
        "      vec.append(0)\n",
        "\n",
        "  # Contains a link (how many)\n",
        "  if \"http://\" in all_message_bodies[i].lower() or \"https://\" in all_message_bodies[i].lower():\n",
        "      vec.append(1)\n",
        "  else:\n",
        "      vec.append(0)\n",
        "\n",
        "  # How many blacklisted phrases/words appear in this email\n",
        "  for b in black_list:\n",
        "      count = 0\n",
        "      for word in b:\n",
        "          if word in all_message_preprocessed[i]:\n",
        "              count += 1\n",
        "      vec.append(count)\n",
        "\n",
        "  # TF-IDF for top terms\n",
        "  for word_weight in tfidf_matrix[i]:\n",
        "      vec.append(word_weight)\n",
        "\n",
        "  # Has all caps word?\n",
        "  vec.append(count_all_upper_words(all_message_bodies[i]))\n",
        "\n",
        "  # Has exclamation marks?\n",
        "  vec.append(all_message_bodies[i].count(\"!\"))\n",
        "\n",
        "  # Total length\n",
        "  vec.append(len(all_message_bodies[i]))\n",
        "\n",
        "  # Num words\n",
        "  vec.append(len(all_message_preprocessed[i]))\n",
        "\n",
        "\n",
        "  all_vectors.append(vec)\n"
      ],
      "metadata": {
        "id": "3EPnNSZ2It9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(all_vectors).shape)\n",
        "print(all_vectors[0])"
      ],
      "metadata": {
        "id": "PZ9bJTmKALk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = []\n",
        "all_labels.extend([1]*len(phishing_preprocessed))\n",
        "all_labels.extend([0]*len(benign_preprocessed))\n",
        "# for i in range(len(phishing_preprocessed)):\n",
        "#     all_labels.append(1)\n",
        "# for i in range(len(benign_preprocessed)):\n",
        "#     all_labels.append(0)"
      ],
      "metadata": {
        "id": "h3weC6JmdGj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_labels))"
      ],
      "metadata": {
        "id": "qidmJuYCUL2D",
        "outputId": "17af97c6-3241-4b15-bada-e699489fb3c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale and split data\n",
        "#scaler = MinMaxScaler()\n",
        "scaler = sk_preprocessing.StandardScaler()\n",
        "scaler.fit(all_vectors)\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(scaler.transform(all_vectors), all_labels, test_size=0.2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "B6_pbP8tdTZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "V9JKyi-3gxfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = ensemble.RandomForestClassifier()\n",
        "#rf = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ri4Rd4omYFgp",
        "outputId": "f9f20fcb-831a-479d-cf70-6c669f713747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf.predict(X_test)\n",
        "rfc_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "rfc_precision = metrics.precision_score(y_test, y_pred)\n",
        "rfc_recall = metrics.recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", rfc_accuracy)\n",
        "print(\"Precision:\", rfc_precision)\n",
        "print(\"Recall:\", rfc_recall)"
      ],
      "metadata": {
        "id": "Srf9IHHTYl4w",
        "outputId": "e454a11c-31d1-4c36-c156-87cc7152f521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "metrics.ConfusionMatrixDisplay(confusion_matrix=cm).plot()"
      ],
      "metadata": {
        "id": "I9x9Z757aI1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVC - Support Vector Classifier"
      ],
      "metadata": {
        "id": "_fkXWY5oBJnf"
      }
    }
  ]
}