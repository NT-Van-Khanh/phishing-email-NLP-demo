{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "eY1C50dpJzKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mailbox\n",
        "import email\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "import nltk.sentiment as sentiment                          #from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# import gensim\n",
        "import gensim.parsing.preprocessing as gs_preprocessing     #from gensim.parsing.preprocessing import *\n",
        "import gensim.corpora as corpora\n",
        "import gensim.models as models                              #from gensim.models import Word2Vec,LdaMulticore\n",
        "#from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# import sklearn\n",
        "import sklearn.feature_extraction.text as text              #from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import sklearn.model_selection as model_selection           #from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "import sklearn.preprocessing as sk_preprocessing            #from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import sklearn.ensemble as ensemble\n",
        "import sklearn.metrics as metrics                           #from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import sklearn.svm as svm                                   #from sklearn.svm import SVC\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "je-Elkn0J3nU",
        "outputId": "873bf3ef-f290-473e-c7a7-419846e25952",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "YraJJFnTQwvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Email"
      ],
      "metadata": {
        "id": "5ZEwrhkOWzXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions: Extract email from .mbox file and .eml file\n"
      ],
      "metadata": {
        "id": "YBf_LlOI-Cnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_emails_from_mbox(mbox_file_name):\n",
        "  messages=[]\n",
        "  try:\n",
        "    mbox = mailbox.mbox(mbox_file_name)\n",
        "    for message in mbox:\n",
        "      messages.append(message)\n",
        "    # messages = [m[1] for m in mbox.items()]\n",
        "  except FileNotFoundError:\n",
        "    print(f\"File not found: {mbox_file_name}\")\n",
        "  return messages\n",
        "\n",
        "\n",
        "def extract_email_from_eml(eml_file_name):\n",
        "  email_message=None\n",
        "  try:\n",
        "      with open(eml_file_name, \"r\") as email_file:\n",
        "          email_message = email.message_from_file(email_file)\n",
        "  except FileNotFoundError:\n",
        "      print(f\"File not found: {eml_file_name}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "  return email_message\n",
        "\n",
        "#From:https://stackoverflow.com/questions/7166922/extracting-the-body-of-an-email-from-mbox-file-decoding-it-to-plain-text-regard"
      ],
      "metadata": {
        "id": "M0vGJHcsbPak"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions: Extract component of email"
      ],
      "metadata": {
        "id": "mJYw16uQIDEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sender_email(email_message):\n",
        "  return email_message.get(\"From\")\n",
        "\n",
        "\n",
        "def extract_subject_email(email_message):\n",
        "  return email_message.get(\"Subject\")\n",
        "\n",
        "\n",
        "def extract_content_email(email_message):\n",
        "  body = None\n",
        "  if(email_message.is_multipart()):\n",
        "    for part in email_message.walk():\n",
        "      if(part.is_multipart()):\n",
        "        for subpart in part.walk():\n",
        "          if(subpart.get_content_type() == \"text/plain\"):\n",
        "            body = subpart.get_payload(decode=True)\n",
        "          # elif(subpart.get_content_type() == \"text/html\"):\n",
        "          #   body = subpart.get_payload(decode=True)\n",
        "      elif(part.get_content_type() == \"text/plain\"):\n",
        "        body = part.get_payload(decode=True)\n",
        "  else:\n",
        "    body = email_message.get_payload(decode=True)\n",
        "  if(body is not None) and isinstance(body, bytes):\n",
        "    #chuyển dữ liệu dạng byte string sang string (utf-8)\n",
        "    try:\n",
        "      body=body.decode('utf-8', errors='ignore')\n",
        "    except UnicodeDecodeError:\n",
        "      # Không làm gì cả nếu lỗi xảy ra, giữ nguyên giá trị body\n",
        "      pass\n",
        "  return body"
      ],
      "metadata": {
        "id": "sBT5Yl7GTPfg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process: Extract phishing emails"
      ],
      "metadata": {
        "id": "HtC14PZmJG_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phishing_message_bodies = []\n",
        "\n",
        "phishing_messages = extract_emails_from_mbox(\"/content/emails-enron-legal-mails.mbox\")\n",
        "for message in phishing_messages:\n",
        "  body=extract_content_email(message)\n",
        "  if (body is not None and body.strip()):\n",
        "    phishing_message_bodies.append(body)\n",
        "    #print(body)\n",
        "    #print(body).decode('utf-8')\n",
        "\n",
        "print(len(phishing_message_bodies))\n",
        "print(len(phishing_messages))"
      ],
      "metadata": {
        "id": "b2FoHAWSGrUw",
        "outputId": "7a0a3c6c-3717-4c4f-e7b0-c5005492af21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4279\n",
            "4279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process: Extract benign emails"
      ],
      "metadata": {
        "id": "dYVDbnwbEUie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benign_message_bodies = []\n",
        "\n",
        "\n",
        "benign_messages = extract_emails_from_mbox(\"/content/emails-enron-ham.mbox\")\n",
        "for message in benign_messages:\n",
        "  body=extract_content_email(message)\n",
        "  if (body is not None and body.strip()):\n",
        "    benign_message_bodies.append(body)\n",
        "\n",
        "print(len(benign_message_bodies))\n",
        "print(len(benign_messages))"
      ],
      "metadata": {
        "id": "pmmlNwehETr0",
        "outputId": "ebac328c-fa9e-4f45-8d69-2541278a5cfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ===TEST==="
      ],
      "metadata": {
        "id": "VQOB1m2h1Tug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msg = extract_email_from_eml(\"/content/sample1.eml\")\n",
        "messages = extract_emails_from_mbox(\"/emails-enron-legal-mails.mbox\")\n",
        "if(msg):\n",
        "  print(extract_sender_email(msg))\n",
        "  print(extract_subject_email(msg))\n",
        "  print(extract_content_email(msg))"
      ],
      "metadata": {
        "id": "LzTM6l8fKWtI",
        "outputId": "ec0bdca7-a6d3-47c8-d62e-751e95e0d53e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File not found: /content/sample1.eml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(phishing_messages[0])\n",
        "print(phishing_message_bodies[0])"
      ],
      "metadata": {
        "id": "ZFt1xuQ61WBe",
        "outputId": "ae5a6ef6-4840-472e-e1a9-b375c44cccbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message-ID: <27151276.1075857703081.JavaMail.evans@thyme>\n",
            "Date: Thu, 28 Dec 2000 16:37:00 -0800 (PST)\n",
            "From: phillip.allen@enron.com\n",
            "To: john.lavorato@enron.com\n",
            "Subject: \n",
            "Mime-Version: 1.0\n",
            "Content-Type: text/plain; charset=ANSI_X3.4-1968\n",
            "Content-Transfer-Encoding: 7bit\n",
            "X-From: Phillip K Allen\n",
            "X-To: Lavorato, John </o=ENRON/ou=NA/cn=Recipients/cn=Jlavora>\n",
            "X-cc: \n",
            "X-bcc: \n",
            "X-Folder: \\jlavora\\COMP\n",
            "X-Origin: Lavorado-J\n",
            "X-FileName: jlavora.pst\n",
            "\n",
            "?\tPay well ? and pay for performance (with bonuses based on merit, not entitlement).\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Just a soundbite from a PRC email.  I am getting worried about Mike G. and myself.  Are you open to more discussions?\n",
            "\n",
            "Phillip\n",
            "\n",
            "\n",
            "?\tPay well ? and pay for performance (with bonuses based on merit, not entitlement).\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "Just a soundbite from a PRC email.  I am getting worried about Mike G. and myself.  Are you open to more discussions?\r\n",
            "\r\n",
            "Phillip\r\n",
            "\r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(benign_messages[0])\n",
        "print(benign_message_bodies[0])"
      ],
      "metadata": {
        "id": "3t1IbwnB1Z2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple preprocessing"
      ],
      "metadata": {
        "id": "jdd-9_Ye04iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom stop words and preprocessing filters"
      ],
      "metadata": {
        "id": "V3njuzeQQOvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom stop words and preprocessing filters\n",
        "stopWords = nltk.corpus.stopwords\n",
        "stopWords = stopWords.words(\"english\")\n",
        "stopWords.extend([\"nbsp\", \"font\", \"sans\", \"serif\", \"bold\", \"arial\", \"verdana\", \"helvetica\", \"http\", \"https\", \"www\", \"html\", \"enron\", \"margin\", \"spamassassin\"])\n",
        "\n",
        "def remove_custom_stopwords(p):\n",
        "    return gs_preprocessing.remove_stopwords(p, stopwords=stopWords)\n",
        "\n",
        "CUSTOM_FILTERS = [lambda x: x.lower(), gs_preprocessing.strip_tags, gs_preprocessing.strip_punctuation,\n",
        "                  gs_preprocessing.strip_multiple_whitespaces, gs_preprocessing.strip_numeric, remove_custom_stopwords,\n",
        "                  gs_preprocessing.remove_stopwords, gs_preprocessing.strip_short, gs_preprocessing.stem_text]\n"
      ],
      "metadata": {
        "id": "ZftALxyg079z"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_preprocessing(messages):\n",
        "  preprocessed_messages = []\n",
        "  for message in messages:\n",
        "    preprocessed = gs_preprocessing.preprocess_string(message,filters = CUSTOM_FILTERS)\n",
        "    #NEED FIX: xu ly trung lap chi can thiet o black list\n",
        "    # if preprocessed and (preprocessed not in preprocessed_messages):\n",
        "    #   preprocessed_messages.append(preprocessed)\n",
        "    preprocessed_messages.append(preprocessed)\n",
        "\n",
        "  return preprocessed_messages\n",
        "\n",
        "#Bỏ các phần tử rỗng và trùng lập\n",
        "def duplicate_filter(texts):\n",
        "    unique_texts = []\n",
        "    for text in texts:\n",
        "        if text and (text not in unique_texts):\n",
        "            unique_texts.append(text)\n",
        "    return unique_texts\n"
      ],
      "metadata": {
        "id": "UHD1wYOMJUom"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess messages"
      ],
      "metadata": {
        "id": "18F0fKdqQTY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing phishing message bodies\n",
        "phishing_preprocessed = []\n",
        "phishing_preprocessed =  custom_preprocessing(phishing_message_bodies)\n",
        "\n",
        "print(len(phishing_preprocessed))"
      ],
      "metadata": {
        "id": "MkbJl5lZ0_SL",
        "outputId": "2b347d47-b562-43c1-8389-28efbde3f4ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing benign message bodies\n",
        "benign_preprocessed = []\n",
        "benign_preprocessed =  custom_preprocessing(benign_message_bodies)\n",
        "\n",
        "print(len(benign_preprocessed))"
      ],
      "metadata": {
        "id": "t2FnvYnt1BWr",
        "outputId": "665681da-29d9-45a4-fc12-969a61894b4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ===TEST==="
      ],
      "metadata": {
        "id": "BWgiCUiuQn7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "print(len(phishing_message_bodies))\n",
        "print(len(duplicate_filter(phishing_message_bodies)))\n",
        "print(len(phishing_preprocessed))\n",
        "print(len(duplicate_filter(phishing_preprocessed)))\n",
        "\n",
        "print(phishing_preprocessed[0])"
      ],
      "metadata": {
        "id": "_0U5tciJ1DKp",
        "outputId": "c179977e-31e7-4c6c-843d-5ca43fcfc623",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4279\n",
            "4246\n",
            "4279\n",
            "4088\n",
            "['pai', 'pai', 'perform', 'bonus', 'base', 'merit', 'entitl', 'soundbit', 'prc', 'email', 'get', 'worri', 'mike', 'open', 'discuss', 'phillip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec Embedding\n"
      ],
      "metadata": {
        "id": "wtANJcvfjMD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_message_preprocessed = phishing_preprocessed + benign_preprocessed\n",
        "\n",
        "print(len(all_message_preprocessed))"
      ],
      "metadata": {
        "id": "r6qsxlGvVccA",
        "outputId": "eb44c98c-5246-4fcd-a072-0b34ff3f7fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on all messages\n",
        "word2vec_model = models.Word2Vec(all_message_preprocessed, vector_size=100, min_count=1, workers=3, window=5)\n",
        "#From: https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/"
      ],
      "metadata": {
        "id": "kRgK9ldSkCtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model.wv.most_similar(\"dollar\", topn=20)"
      ],
      "metadata": {
        "id": "3e4GPHLjluvu",
        "outputId": "23d0d51c-cd0d-4fbc-d0f9-915970d8236e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('billion', 0.9507895112037659),\n",
              " ('win', 0.9110546112060547),\n",
              " ('ubid', 0.903036892414093),\n",
              " ('maximum', 0.8959468603134155),\n",
              " ('tend', 0.8940055966377258),\n",
              " ('quantiti', 0.8918537497520447),\n",
              " ('supersit', 0.8888633251190186),\n",
              " ('defici', 0.8846665024757385),\n",
              " ('prioriti', 0.8796712160110474),\n",
              " ('half', 0.8794583082199097),\n",
              " ('auction', 0.8794552087783813),\n",
              " ('size', 0.8770312666893005),\n",
              " ('dissent', 0.8762837648391724),\n",
              " ('entri', 0.8752008080482483),\n",
              " ('dcq', 0.8745139837265015),\n",
              " ('store', 0.8734740018844604),\n",
              " ('majeur', 0.8722878098487854),\n",
              " ('grab', 0.8720036149024963),\n",
              " ('shorter', 0.8716081380844116),\n",
              " ('furthermor', 0.8704047203063965)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model.wv[\"dollar\"]"
      ],
      "metadata": {
        "id": "ykaw9PxJlvup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA Topic Modeling"
      ],
      "metadata": {
        "id": "j8sFzX6jU8mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init the number of topics"
      ],
      "metadata": {
        "id": "ZpBNSKMUWhQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numTopics = 1024"
      ],
      "metadata": {
        "id": "_d1CZXaGVRy8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create dictionary and corpus"
      ],
      "metadata": {
        "id": "aguwb1mdVu4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = corpora.Dictionary(all_message_preprocessed)\n",
        "corpus = [dictionary.doc2bow(text) for text in all_message_preprocessed]"
      ],
      "metadata": {
        "id": "5aw2MNILTy1w"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterator = iter(dictionary.items())\n",
        "print([next(iterator) for _ in range(6)])\n",
        "print(corpus[0])"
      ],
      "metadata": {
        "id": "YPhs2VaHPZqj",
        "outputId": "03fc9285-1c48-4ea9-c52a-a56eb4f8cb22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'base'), (1, 'bonus'), (2, 'discuss'), (3, 'email'), (4, 'entitl'), (5, 'get')]\n",
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Create LDA model"
      ],
      "metadata": {
        "id": "efVePDN9VySO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LDA_model = models.LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=numTopics)"
      ],
      "metadata": {
        "id": "TbqOjNTPXTVA",
        "outputId": "8853017f-baa6-472a-8ba8-fa84652cf6f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "# Print keyword for the topics\n",
        "print(LDA_model.print_topics())"
      ],
      "metadata": {
        "id": "SNJqzs9mZ3wR",
        "outputId": "b98665e4-67a3-43cf-87bd-df2d494d512c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(204, '0.015*\"ect\" + 0.010*\"hou\" + 0.007*\"need\" + 0.007*\"deliveri\" + 0.007*\"nebraska\" + 0.007*\"texa\" + 0.006*\"rate\" + 0.006*\"zone\" + 0.006*\"mark\" + 0.005*\"beer\"'), (994, '0.015*\"com\" + 0.007*\"contract\" + 0.005*\"oper\" + 0.005*\"dai\" + 0.005*\"audit\" + 0.004*\"propos\" + 0.004*\"chang\" + 0.004*\"parti\" + 0.004*\"perform\" + 0.004*\"time\"'), (352, '0.016*\"ect\" + 0.010*\"contract\" + 0.009*\"dai\" + 0.008*\"gisb\" + 0.006*\"fgu\" + 0.006*\"lon\" + 0.006*\"citi\" + 0.006*\"com\" + 0.005*\"parti\" + 0.005*\"attach\"'), (76, '0.008*\"plan\" + 0.007*\"save\" + 0.006*\"wessex\" + 0.006*\"ee\" + 0.006*\"com\" + 0.005*\"water\" + 0.005*\"power\" + 0.005*\"contract\" + 0.004*\"util\" + 0.004*\"rate\"'), (177, '0.133*\"com\" + 0.022*\"mail\" + 0.010*\"socalga\" + 0.009*\"sempra\" + 0.006*\"david\" + 0.005*\"jame\" + 0.005*\"robert\" + 0.005*\"org\" + 0.004*\"mark\" + 0.004*\"john\"'), (356, '0.016*\"com\" + 0.012*\"certif\" + 0.011*\"jim\" + 0.010*\"iso\" + 0.010*\"client\" + 0.010*\"man\" + 0.010*\"inform\" + 0.009*\"market\" + 0.009*\"januari\" + 0.007*\"mail\"'), (598, '0.011*\"kevin\" + 0.010*\"com\" + 0.010*\"ted\" + 0.008*\"ee\" + 0.007*\"subject\" + 0.007*\"good\" + 0.006*\"hou\" + 0.005*\"friend\" + 0.005*\"said\" + 0.005*\"parent\"'), (462, '0.058*\"com\" + 0.013*\"transwestern\" + 0.011*\"needl\" + 0.010*\"subject\" + 0.010*\"deliveri\" + 0.010*\"messag\" + 0.009*\"north\" + 0.008*\"jame\" + 0.008*\"primari\" + 0.008*\"david\"'), (716, '0.107*\"com\" + 0.010*\"scott\" + 0.009*\"good\" + 0.008*\"susan\" + 0.007*\"lisa\" + 0.007*\"content\" + 0.007*\"week\" + 0.007*\"stephan\" + 0.007*\"time\" + 0.007*\"frank\"'), (10, '0.050*\"ect\" + 0.030*\"hou\" + 0.021*\"develop\" + 0.014*\"enronxg\" + 0.013*\"ee\" + 0.011*\"corp\" + 0.007*\"board\" + 0.007*\"deal\" + 0.007*\"power\" + 0.007*\"commun\"'), (779, '0.058*\"ect\" + 0.032*\"market\" + 0.025*\"pdx\" + 0.020*\"counterparti\" + 0.018*\"correct\" + 0.017*\"list\" + 0.014*\"report\" + 0.014*\"incorrect\" + 0.014*\"power\" + 0.013*\"click\"'), (568, '0.149*\"com\" + 0.008*\"lisa\" + 0.006*\"john\" + 0.005*\"smith\" + 0.004*\"lesli\" + 0.004*\"syme\" + 0.004*\"ect\" + 0.004*\"tom\" + 0.004*\"chang\" + 0.004*\"scott\"'), (867, '0.170*\"com\" + 0.013*\"jmbm\" + 0.012*\"internet\" + 0.011*\"nco\" + 0.007*\"lisa\" + 0.005*\"richard\" + 0.005*\"john\" + 0.004*\"susan\" + 0.004*\"syme\" + 0.004*\"jeremi\"'), (890, '0.021*\"ect\" + 0.015*\"hou\" + 0.014*\"com\" + 0.010*\"hill\" + 0.009*\"richard\" + 0.008*\"judg\" + 0.008*\"market\" + 0.007*\"subject\" + 0.007*\"corp\" + 0.006*\"attend\"'), (516, '0.043*\"ect\" + 0.038*\"com\" + 0.033*\"mpg\" + 0.026*\"hou\" + 0.020*\"attach\" + 0.019*\"scott\" + 0.014*\"susan\" + 0.011*\"olymp\" + 0.011*\"subject\" + 0.011*\"file\"'), (215, '0.019*\"ga\" + 0.013*\"com\" + 0.013*\"california\" + 0.009*\"said\" + 0.009*\"price\" + 0.009*\"trade\" + 0.007*\"need\" + 0.007*\"want\" + 0.006*\"ect\" + 0.006*\"market\"'), (90, '0.142*\"com\" + 0.008*\"joe\" + 0.008*\"ect\" + 0.007*\"kate\" + 0.006*\"paul\" + 0.006*\"john\" + 0.006*\"mark\" + 0.006*\"chang\" + 0.005*\"chri\" + 0.005*\"georg\"'), (851, '0.064*\"ect\" + 0.022*\"travel\" + 0.020*\"hou\" + 0.019*\"com\" + 0.014*\"southwest\" + 0.013*\"purchas\" + 0.013*\"fare\" + 0.011*\"pdx\" + 0.009*\"januari\" + 0.009*\"begin\"'), (184, '0.017*\"com\" + 0.014*\"blair\" + 0.013*\"lynn\" + 0.011*\"custom\" + 0.010*\"bradlei\" + 0.010*\"ramona\" + 0.010*\"betancourt\" + 0.009*\"train\" + 0.008*\"holm\" + 0.008*\"maggi\"'), (154, '0.031*\"ect\" + 0.022*\"com\" + 0.012*\"curv\" + 0.012*\"hou\" + 0.010*\"subject\" + 0.008*\"joshua\" + 0.008*\"corp\" + 0.008*\"factor\" + 0.008*\"draft\" + 0.007*\"forward\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Doc2Vec"
      ],
      "metadata": {
        "id": "K-V4GinQabbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_data = [models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(all_message_preprocessed)]"
      ],
      "metadata": {
        "id": "aC8vWlZ3aezK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Khởi tạo và huấn luyện trực tiếp\n",
        "doc2vec_model = models.Doc2Vec(tagged_data, vector_size=20, window=2, min_count=1, workers=4)\n",
        "\n",
        "#Tách khởi tạo và huấn luyện1\n",
        "# doc2vec_model = models.Doc2Vec(tagged_data, vector_size=100, min_count=1, epochs=10)\n",
        "# doc2vec_model.build_vocab(tagged_data)\n",
        "# doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)"
      ],
      "metadata": {
        "id": "5_JOKTTzfDMP"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification"
      ],
      "metadata": {
        "id": "EDQ0WAcNK4Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_message_bodies = phishing_message_bodies + benign_message_bodies"
      ],
      "metadata": {
        "id": "04yicyRHSvSv"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blacklist words"
      ],
      "metadata": {
        "id": "QeuddVD5-Knt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_lines(file_path):\n",
        "  lines=[]\n",
        "  try:\n",
        "    with open(file_path, 'r') as file:\n",
        "      for line in file:\n",
        "        lines.append(line.strip())\n",
        "  except FileNotFoundError:\n",
        "    print(f\"File not found: {file_path}\")\n",
        "  return lines"
      ],
      "metadata": {
        "id": "h9VMJIFaDX3T"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "black_list_words = get_file_lines(\"/content/spam_wordlist.txt\")\n",
        "black_list = custom_preprocessing(black_list_words)\n",
        "black_list = duplicate_filter(black_list)\n",
        "\n",
        "print(len(black_list_words))\n",
        "print(len(black_list))"
      ],
      "metadata": {
        "id": "D87FfTy6Rj9T",
        "outputId": "5df9fe7e-9a73-4550-d494-41ae0c203f08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File not found: /content/spam_wordlist.txt\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "00E_wzpVqh8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF\n",
        "max_term=6"
      ],
      "metadata": {
        "id": "SpzXq0S4VWxY"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_to_string(lst):\n",
        "    return ' '.join(lst)\n",
        "\n",
        "def count_all_upper_words(text):\n",
        "    count = 0\n",
        "    for word in text.split():\n",
        "        if word.isupper():\n",
        "            count += 1\n",
        "    return count"
      ],
      "metadata": {
        "id": "x0PWX0K9ctOe"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfVectorizer = text.TfidfVectorizer(max_features=max_term, preprocessor=list_to_string, sublinear_tf=True)\n",
        "tfidf_matrix = tfidfVectorizer.fit_transform(all_message_preprocessed).toarray()\n",
        "\n",
        "print(tfidfVectorizer.get_feature_names_out())\n",
        "print(tfidf_matrix.shape)\n",
        "print(tfidf_matrix[2])"
      ],
      "metadata": {
        "id": "eRfu_3cSYF0q",
        "outputId": "185c23eb-5572-4818-df35-90199d23765a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['com' 'content' 'ect' 'hou' 'mail' 'subject']\n",
            "(4279, 6)\n",
            "[0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector"
      ],
      "metadata": {
        "id": "GnnS-cy7-Etr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vectors_from_messages(messages, messages_preprocessed):\n",
        "    corpus = [dictionary.doc2bow(text) for text in messages_preprocessed] # Term document frequency\n",
        "    all_vectors = []\n",
        "    for i in range(len(messages)):\n",
        "        topTopics = LDA_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
        "\n",
        "        # Can extend this array with other stuff later\n",
        "        vec = [topTopics[i][1] for i in range(numTopics)] # Topics\n",
        "\n",
        "        for v in doc2vec_model.infer_vector(messages_preprocessed[i]): # Doc2Vec\n",
        "            vec.append(v)\n",
        "\n",
        "        # Sentiment analysis of polarity\n",
        "        sia = sentiment.SentimentIntensityAnalyzer()\n",
        "        sentence = \" \".join(messages_preprocessed[i])\n",
        "        polarity = sia.polarity_scores(sentence)\n",
        "        for s in polarity:\n",
        "            vec.append(polarity[s])\n",
        "\n",
        "        # Contains HTML\n",
        "        if \"<html>\" in messages[i].lower():\n",
        "            vec.append(1)\n",
        "        else:\n",
        "            vec.append(0)\n",
        "\n",
        "        # Contains a link\n",
        "        if \"http://\" in messages[i].lower() or \"https://\" in messages[i].lower():\n",
        "            vec.append(1)\n",
        "        else:\n",
        "            vec.append(0)\n",
        "\n",
        "        # How many blacklisted phrases/words appear in this email\n",
        "        for b in black_list:\n",
        "            count = 0\n",
        "            for word in b:\n",
        "                if word in messages_preprocessed[i]:\n",
        "                    count += 1\n",
        "            vec.append(count)\n",
        "\n",
        "        # TF-IDF for top terms\n",
        "        for word_weight in tfidf_matrix[i]:\n",
        "            vec.append(word_weight)\n",
        "\n",
        "        # Has all caps word?\n",
        "        vec.append(count_all_upper_words(messages[i]))\n",
        "\n",
        "        # Has exclamation marks?\n",
        "        vec.append(messages[i].count(\"!\"))\n",
        "\n",
        "        # Total length\n",
        "        vec.append(len(messages[i]))\n",
        "\n",
        "        # Num words\n",
        "        vec.append(len(messages_preprocessed[i]))\n",
        "\n",
        "        all_vectors.append(vec)\n",
        "\n",
        "    return all_vectors"
      ],
      "metadata": {
        "id": "UD7_5yfM9Cw6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_vectors = []\n",
        "for i in range(len(all_message_bodies)):\n",
        "  top_topics = LDA_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
        "  vec =  [top_topics[i][1] for i in range(numTopics)]#topics\n",
        "\n",
        "  for v in doc2vec_model.infer_vector(all_message_preprocessed[i]):#Doc2Vec--need to fix\n",
        "    vec.append(v)\n",
        "\n",
        "  sia = sentiment.SentimentIntensityAnalyzer()\n",
        "  sentence = \" \".join(all_message_preprocessed[i])\n",
        "  polarity = sia.polarity_scores(sentence)\n",
        "\n",
        "  for s in polarity:\n",
        "    vec.append(polarity[s])\n",
        "\n",
        "  # Contains HTML\n",
        "  if \"<html>\" in all_message_bodies[i].lower():\n",
        "      vec.append(1)\n",
        "  else:\n",
        "      vec.append(0)\n",
        "\n",
        "  # Contains a link (how many)\n",
        "  if \"http://\" in all_message_bodies[i].lower() or \"https://\" in all_message_bodies[i].lower():\n",
        "      vec.append(1)\n",
        "  else:\n",
        "      vec.append(0)\n",
        "\n",
        "  # How many blacklisted phrases/words appear in this email\n",
        "  for b in black_list:\n",
        "      count = 0\n",
        "      for word in b:\n",
        "          if word in all_message_preprocessed[i]:\n",
        "              count += 1\n",
        "      vec.append(count)\n",
        "\n",
        "  # TF-IDF for top terms\n",
        "  for word_weight in tfidf_matrix[i]:\n",
        "      vec.append(word_weight)\n",
        "\n",
        "  # Has all caps word?\n",
        "  vec.append(count_all_upper_words(all_message_bodies[i]))\n",
        "\n",
        "  # Has exclamation marks?\n",
        "  vec.append(all_message_bodies[i].count(\"!\"))\n",
        "\n",
        "  # Total length\n",
        "  vec.append(len(all_message_bodies[i]))\n",
        "\n",
        "  # Num words\n",
        "  vec.append(len(all_message_preprocessed[i]))\n",
        "\n",
        "\n",
        "  all_vectors.append(vec)\n"
      ],
      "metadata": {
        "id": "3EPnNSZ2It9e"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(all_vectors).shape)\n",
        "print(all_vectors[0])"
      ],
      "metadata": {
        "id": "PZ9bJTmKALk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = []\n",
        "all_labels.extend([1]*len(phishing_preprocessed))\n",
        "all_labels.extend([0]*len(benign_preprocessed))\n",
        "# for i in range(len(phishing_preprocessed)):\n",
        "#     all_labels.append(1)\n",
        "# for i in range(len(benign_preprocessed)):\n",
        "#     all_labels.append(0)"
      ],
      "metadata": {
        "id": "h3weC6JmdGj1"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_labels))"
      ],
      "metadata": {
        "id": "qidmJuYCUL2D",
        "outputId": "17af97c6-3241-4b15-bada-e699489fb3c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale and split data\n",
        "#scaler = MinMaxScaler()\n",
        "scaler = sk_preprocessing.StandardScaler()\n",
        "scaler.fit(all_vectors)\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(scaler.transform(all_vectors), all_labels, test_size=0.2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "B6_pbP8tdTZR"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "V9JKyi-3gxfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = ensemble.RandomForestClassifier()\n",
        "#rf = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ri4Rd4omYFgp",
        "outputId": "29b2236e-b9d5-4db0-c7a0-b965005e6fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "rfc_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "rfc_precision = metrics.precision_score(y_test, y_pred)\n",
        "rfc_recall = metrics.recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", rfc_accuracy)\n",
        "print(\"Precision:\", rfc_precision)\n",
        "print(\"Recall:\", rfc_recall)"
      ],
      "metadata": {
        "id": "Srf9IHHTYl4w",
        "outputId": "e454a11c-31d1-4c36-c156-87cc7152f521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "metrics.ConfusionMatrixDisplay(confusion_matrix=cm).plot()"
      ],
      "metadata": {
        "id": "I9x9Z757aI1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process: Extract emails to test"
      ],
      "metadata": {
        "id": "9V9A56Z4wMYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_messages = extract_emails_from_mbox(\"/content/emails-enron-legal-mails.mbox\")\n",
        "test_message_bodies = [extract_content_email(message) for message in test_messages]\n",
        "# Apply preprocessing function to emails\n",
        "test_messages_preprocessed = custom_preprocessing(test_message_bodies)"
      ],
      "metadata": {
        "id": "no0oniQ9ndkS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_vector_test = create_vectors_from_messages(test_message_bodies, test_messages_preprocessed)"
      ],
      "metadata": {
        "id": "5qX1yw4gvuRY"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RFC Prediction\n",
        "X = scaler.transform(all_vector_test)\n",
        "y_pred = rf.predict(X)\n",
        "\n",
        "num_phishing = 0\n",
        "for i in y_pred:\n",
        "  if i == 1:\n",
        "    num_phishing += 1\n",
        "\n",
        "print(\"Number of phishing emails:\", num_phishing)\n",
        "print(\"Number of benign emails:\", len(y_pred) - num_phishing)"
      ],
      "metadata": {
        "id": "P_jDt8n_9gv6",
        "outputId": "d2ef1521-71f7-4928-e561-fc333f726b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of phishing emails: 4279\n",
            "Number of benign emails: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_message_bodies[100])\n",
        "print(test_messages_preprocessed[100])"
      ],
      "metadata": {
        "id": "g4p8P9jww2Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of messages: {}\".format(np.array(all_vector_test).shape))"
      ],
      "metadata": {
        "id": "0iS5PObjw3_8",
        "outputId": "f568a817-cb05-4020-e885-2d1c5476fdf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of messages: (4279, 1060)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVC - Support Vector Classifier"
      ],
      "metadata": {
        "id": "_fkXWY5oBJnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc = svm.SVC(gamma=\"auto\")\n",
        "svc.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "LNDTKkGO8vJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svc.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "precision = metrics.precision_score(y_test, y_pred)\n",
        "recall = metrics.recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "id": "-EKUmlaiH2R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "metrics.ConfusionMatrixDisplay(confusion_matrix=cm).plot()"
      ],
      "metadata": {
        "id": "A_Hkxmm5MNRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Learning ConvNet"
      ],
      "metadata": {
        "id": "psxGPyRRMXFT"
      }
    }
  ]
}